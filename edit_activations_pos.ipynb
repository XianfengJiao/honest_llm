{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from einops import rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_head_wise = pkl.load(open('/data/jxf/activations/llama_7B_tqa_mc2_all_head_wise.pkl', 'rb'))\n",
    "activation_head_wise_end = pkl.load(open('/data/jxf/activations/llama_7B_tqa_mc2_all_100_head_wise.pkl', 'rb'))\n",
    "activation_categories = pkl.load(open('/data/jxf/activations/llama_7B_tqa_mc2_all_categories.pkl', 'rb'))\n",
    "activation_labels = np.load('/data/jxf/activations/llama_7B_tqa_mc2_all_labels.npy')\n",
    "activation_tokens = pkl.load(open('/data/jxf/activations/llama_7B_tqa_mc2_all_tokens.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_separated_activations(labels, head_wise_activations, categories): \n",
    "\n",
    "    # separate activations by question\n",
    "    dataset=load_dataset('truthful_qa', 'multiple_choice')['validation']\n",
    "    actual_labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        actual_labels.append(dataset[i]['mc2_targets']['labels'])\n",
    "    \n",
    "\n",
    "    idxs_to_split_at = np.cumsum([len(x) for x in actual_labels])        \n",
    "\n",
    "    labels = list(labels)\n",
    "    categories = list(categories)\n",
    "    separated_labels = []\n",
    "    separated_categories = []\n",
    "    for i in range(len(idxs_to_split_at)):\n",
    "        if i == 0:\n",
    "            separated_labels.append(labels[:idxs_to_split_at[i]])\n",
    "            separated_categories.append(categories[:idxs_to_split_at[i]])\n",
    "        else:\n",
    "            separated_labels.append(labels[idxs_to_split_at[i-1]:idxs_to_split_at[i]])\n",
    "            separated_categories.append(categories[idxs_to_split_at[i-1]:idxs_to_split_at[i]])\n",
    "\n",
    "    separated_head_wise_activations = np.split(head_wise_activations, idxs_to_split_at)\n",
    "\n",
    "    return separated_head_wise_activations, separated_labels, separated_categories, idxs_to_split_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_pos(tokens):\n",
    "    positions = []\n",
    "    for token_list in tokens:\n",
    "        for i in range(0, len(token_list)-1):\n",
    "            if ('?' in token_list[i] or token_list[i] == '.') and token_list[i+1] == '▁A':\n",
    "                positions.append(i)  # 将找到的位置添加到列表中\n",
    "                break  # 假设每个列表中只有一个满足条件的位置\n",
    "        if i == len(token_list)-2:\n",
    "            print('Error: cannot find question')\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_pos = find_q_pos(activation_tokens)\n",
    "# q_activation_head_wise = [activations[:, pos, :] for activations, pos in zip(activation_head_wise, q_pos)]\n",
    "# pkl.dump(q_activation_head_wise, open('/data/jxf/activations/llama_7B_tqa_mc2_question_head_wise.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 4096)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_head_wise_end[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset truthful_qa (/data/wtl/hf_cache/truthful_qa/multiple_choice/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 726.54it/s]\n"
     ]
    }
   ],
   "source": [
    "separated_head_wise_activations, separated_labels, separated_categories, idxs_to_split_at = get_separated_activations(activation_labels, activation_head_wise_end, activation_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_wise_activation_directions = [a[np.array(l) == 1].mean(axis=0) - a[np.array(l) == 0].mean(axis=0) for a, l in zip(separated_head_wise_activations, separated_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 32\n",
    "head_wise_activation_directions = rearrange(head_wise_activation_directions, 'b s (h d) -> b s h d', h=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 32, 32, 128)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_wise_activation_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset truthful_qa (/data/wtl/hf_cache/truthful_qa/multiple_choice/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 568.80it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")['validation']\n",
    "df = pd.read_csv('./TruthfulQA/data/v0/TruthfulQA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [00:27<00:00, 29.92it/s]\n"
     ]
    }
   ],
   "source": [
    "df['Direction'] = 0\n",
    "for i in tqdm(range(len(dataset))): \n",
    "    q = dataset[i]['question']\n",
    "    direction = head_wise_activation_directions[i]\n",
    "    df.loc[df['Question'] == q, 'Direction'] = [direction.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./TruthfulQA/data/v0/TruthfulQA_head_wise_end_direction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(head_wise_activation_directions, open('/data/jxf/activations/llama_7B_tqa_mc2_all_100_head_wise_directions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
